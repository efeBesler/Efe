{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THg0PIa7kZwz","executionInfo":{"status":"ok","timestamp":1710152392906,"user_tz":-180,"elapsed":1470,"user":{"displayName":"Cenk Demiroglu","userId":"07704308817729932955"}},"outputId":"d479799a-91fc-4717-a6c2-97e962656e74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/200], Loss: 0.1934, First layer gradient norm: 0.0293\n","Epoch [21/200], Loss: 0.0172, First layer gradient norm: 0.0154\n","Epoch [41/200], Loss: 0.0088, First layer gradient norm: 0.0105\n","Epoch [61/200], Loss: 0.0034, First layer gradient norm: 0.0064\n","Epoch [81/200], Loss: 0.0007, First layer gradient norm: 0.0026\n","Epoch [101/200], Loss: 0.0002, First layer gradient norm: 0.0004\n","Epoch [121/200], Loss: 0.0001, First layer gradient norm: 0.0002\n","Epoch [141/200], Loss: 0.0001, First layer gradient norm: 0.0001\n","Epoch [161/200], Loss: 0.0000, First layer gradient norm: 0.0000\n","Epoch [181/200], Loss: 0.0000, First layer gradient norm: 0.0000\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","# Define a simple RNN model\n","class SimpleRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(SimpleRNN, self).__init__()\n","        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        out, _ = self.rnn(x)\n","        out = self.fc(out)\n","        return out\n","\n","# Parameters\n","input_size = 1\n","hidden_size = 10  # Small hidden size to make the effect more pronounced\n","output_size = 1\n","sequence_length = 50  # Try varying this to see the effect on vanishing gradients\n","\n","# Initialize the model\n","model = SimpleRNN(input_size, hidden_size, output_size)\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Synthetic dataset: input is a sequence of zeros with a one at the end, target is the same\n","inputs = torch.zeros(1, sequence_length, 1)\n","inputs[:, -1, 0] = 1  # Set the last input to one\n","targets = inputs.clone()  # Target is the same as input\n","\n","# Training loop\n","for epoch in range(200):\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    loss = criterion(outputs, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Check and print the gradient norms for the first layer weights\n","    if epoch % 20 == 0:\n","        first_layer_gradients_norm = model.rnn.weight_ih_l0.grad.norm().item()\n","        print(f'Epoch [{epoch+1}/200], Loss: {loss.item():.4f}, First layer gradient norm: {first_layer_gradients_norm:.4f}')\n","\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}